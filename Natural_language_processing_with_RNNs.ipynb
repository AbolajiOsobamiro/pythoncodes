{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbolajiOsobamiro/pythoncodes/blob/main/Natural_language_processing_with_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FaKpuJkm1M3E"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aqQbp2EE3bPO"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPEqabiQ0sSy"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "path_to_file = list(files.upload().keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BlC9ED1X4ykp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60597157-172e-4a8a-ba36-9654b2cb0d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 86091 characters\n"
          ]
        }
      ],
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EKRn6C7S6SZL"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i,u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azNKA1tV7Pak"
      },
      "outputs": [],
      "source": [
        "print('Original Text: ',text[:13])\n",
        "print('Encoded Text: ' ,text_to_int(text[:13]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UndzOyt8bHq"
      },
      "outputs": [],
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints=ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return(''.join(idx2char[ints]))\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5t7Y77fQJgv7"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length + 1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MLrWOg91KRpa"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EjEnw2iALI0i"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjfVn7r4MR7P"
      },
      "outputs": [],
      "source": [
        "for x,y in dataset.take(2):\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print('INPUT')\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "gdL83x07NGJw"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlIOPNqJO8m6"
      },
      "outputs": [],
      "source": [
        "def build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE):\n",
        "  model= tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM,\n",
        "                                batch_input_shape =[BATCH_SIZE, None]),\n",
        "      tf.keras.layers.LSTM(\n",
        "          RNN_UNITS,\n",
        "          return_sequences = True,\n",
        "          stateful = True,\n",
        "          recurrent_initializer = 'glorot_uniform'),\n",
        "      tf.keras.layers.Dense(VOCAB_SIZE)\n",
        "\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model= build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8z95Ea9eQav"
      },
      "outputs": [],
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"#(BATCH_SIZE, seq_length,VOCAB_SIZE)\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x35UAHqUfKao"
      },
      "outputs": [],
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4_j89HwfjVQ"
      },
      "outputs": [],
      "source": [
        "pred=example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BgRDO37fxKJ"
      },
      "outputs": [],
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cm4Qqvtg8tq"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1,-1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0RFl0uvRhlwf"
      },
      "outputs": [],
      "source": [
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "UtRTqUZYiJ4q"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "iRlBent9iTqB"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "i-4N50pgjKQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bae7dfc-8834-4d86-dea1-ff95a77b00bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "13/13 [==============================] - 4s 107ms/step - loss: 3.9846\n",
            "Epoch 2/40\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 3.4650\n",
            "Epoch 3/40\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 3.3837\n",
            "Epoch 4/40\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 3.2792\n",
            "Epoch 5/40\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 3.1176\n",
            "Epoch 6/40\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 2.8958\n",
            "Epoch 7/40\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 2.6609\n",
            "Epoch 8/40\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 2.5121\n",
            "Epoch 9/40\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 2.4186\n",
            "Epoch 10/40\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 2.3530\n",
            "Epoch 11/40\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 2.2959\n",
            "Epoch 12/40\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 2.2444\n",
            "Epoch 13/40\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 2.2013\n",
            "Epoch 14/40\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 2.1581\n",
            "Epoch 15/40\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 2.1171\n",
            "Epoch 16/40\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 2.0793\n",
            "Epoch 17/40\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 2.0410\n",
            "Epoch 18/40\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 2.0075\n",
            "Epoch 19/40\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 1.9711\n",
            "Epoch 20/40\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 1.9395\n",
            "Epoch 21/40\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 1.9032\n",
            "Epoch 22/40\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.8722\n",
            "Epoch 23/40\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 1.8427\n",
            "Epoch 24/40\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 1.8134\n",
            "Epoch 25/40\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.7873\n",
            "Epoch 26/40\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 1.7600\n",
            "Epoch 27/40\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.7298\n",
            "Epoch 28/40\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 1.7066\n",
            "Epoch 29/40\n",
            "13/13 [==============================] - 1s 98ms/step - loss: 1.6812\n",
            "Epoch 30/40\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 1.6582\n",
            "Epoch 31/40\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 1.6335\n",
            "Epoch 32/40\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 1.6119\n",
            "Epoch 33/40\n",
            "13/13 [==============================] - 2s 110ms/step - loss: 1.5889\n",
            "Epoch 34/40\n",
            "13/13 [==============================] - 2s 103ms/step - loss: 1.5669\n",
            "Epoch 35/40\n",
            "13/13 [==============================] - 2s 112ms/step - loss: 1.5480\n",
            "Epoch 36/40\n",
            "13/13 [==============================] - 2s 96ms/step - loss: 1.5287\n",
            "Epoch 37/40\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 1.5031\n",
            "Epoch 38/40\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 1.4828\n",
            "Epoch 39/40\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.4621\n",
            "Epoch 40/40\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.4423\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(data, epochs=40, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zs7Fs1nCV0G3"
      },
      "outputs": [],
      "source": [
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "41AxdF6dWCIt"
      },
      "outputs": [],
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "pRa77cr2YMdK"
      },
      "outputs": [],
      "source": [
        "model.save_weights(checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ari-QFAacILX"
      },
      "outputs": [],
      "source": [
        "checkpoint_num = 10\n",
        "checkpoint_path = \"./training_checkpoints/ckpt_\" + str(checkpoint_num)\n",
        "model.load_weights(checkpoint_path)\n",
        "model.build(tf.TensorShape([1,None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0looJyo7ZlfV"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 1000\n",
        "\n",
        "  input_eval= [char2idx[s] for s in start_string]\n",
        "  input_eval= tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 1.0\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string +''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVExp4TbcVAx"
      },
      "outputs": [],
      "source": [
        "inp =  input('Type a starting string: ')\n",
        "print(generate_text(model,inp))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPbCAXViFuCrzSZaODyrl+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}